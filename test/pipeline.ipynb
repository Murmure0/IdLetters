{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_to_fr = pipeline(\"translation_en_to_fr\",\n",
    "                    model=\"Helsinki-NLP/opus-mt-en-fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"J'aime vraiment ton style.\"}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_to_fr(\"I really like your style\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_to_en = pipeline('translation_fr_to_en',\n",
    "                    model = \"Helsinki-NLP/opus-mt-fr-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = fr_to_en(\"Votre droit aux allocations en tant que chômeur complet travailleur à temps partiel volontaire.Bonjour MAELLE BERTHET,Par cette lettre, nous vous informons de vos droits aux allocations en tant que chômeur complet travailleur à temps partiel volontaire, à la suite de votre demande ou de votre déclaration d'un événement modificatif, prenant cours le 10/12/2022.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Your entitlement to benefits as a full-time, voluntary part-time worker.Hello MAELLE BERTHET,By this letter, we inform you of your entitlement to benefits as a full-time, voluntary part-time worker, following your request or declaration of an amending event, taking place on 10/12/2022.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your entitlement to benefits as a full-time, voluntary part-time worker.\n",
      "Hello MAELLE BERTHET,By this letter, we inform you of your entitlement to benefits as a full-time, voluntary part-time worker, following your request or declaration of an amending event, taking place on 10/12/2022.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "tmp = ret[0]['translation_text']\n",
    "tmp = tmp.replace(\".\", \".\\n\")\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m summarize \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39;49m\u001b[39msummarization\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      2\u001b[0m                      model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtuner007/pegasus_summarizer\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\admindc\\anaconda3\\envs\\tf_devia\\lib\\site-packages\\transformers\\pipelines\\__init__.py:788\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    787\u001b[0m     model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[1;32m--> 788\u001b[0m     framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    789\u001b[0m         model,\n\u001b[0;32m    790\u001b[0m         model_classes\u001b[39m=\u001b[39mmodel_classes,\n\u001b[0;32m    791\u001b[0m         config\u001b[39m=\u001b[39mconfig,\n\u001b[0;32m    792\u001b[0m         framework\u001b[39m=\u001b[39mframework,\n\u001b[0;32m    793\u001b[0m         task\u001b[39m=\u001b[39mtask,\n\u001b[0;32m    794\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs,\n\u001b[0;32m    795\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    796\u001b[0m     )\n\u001b[0;32m    798\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    799\u001b[0m hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32mc:\\Users\\admindc\\anaconda3\\envs\\tf_devia\\lib\\site-packages\\transformers\\pipelines\\base.py:269\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    264\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    265\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTrying to load the model with Tensorflow.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m     )\n\u001b[0;32m    268\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 269\u001b[0m     model \u001b[39m=\u001b[39m model_class\u001b[39m.\u001b[39mfrom_pretrained(model, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39meval\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    271\u001b[0m         model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\admindc\\anaconda3\\envs\\tf_devia\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:493\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    492\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 493\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    494\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39mmodel_args, config\u001b[39m=\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    495\u001b[0m     )\n\u001b[0;32m    496\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    497\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    498\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\admindc\\anaconda3\\envs\\tf_devia\\lib\\site-packages\\transformers\\modeling_utils.py:2700\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2697\u001b[0m     init_contexts\u001b[39m.\u001b[39mappend(init_empty_weights())\n\u001b[0;32m   2699\u001b[0m \u001b[39mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m-> 2700\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(config, \u001b[39m*\u001b[39mmodel_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2702\u001b[0m \u001b[39m# Check first if we are `from_pt`\u001b[39;00m\n\u001b[0;32m   2703\u001b[0m \u001b[39mif\u001b[39;00m use_keep_in_fp32_modules:\n",
      "File \u001b[1;32mc:\\Users\\admindc\\anaconda3\\envs\\tf_devia\\lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py:1316\u001b[0m, in \u001b[0;36mPegasusForConditionalGeneration.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m   1314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config: PegasusConfig):\n\u001b[0;32m   1315\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(config)\n\u001b[1;32m-> 1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m PegasusModel(config)\n\u001b[0;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister_buffer(\u001b[39m\"\u001b[39m\u001b[39mfinal_logits_bias\u001b[39m\u001b[39m\"\u001b[39m, torch\u001b[39m.\u001b[39mzeros((\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mshared\u001b[39m.\u001b[39mnum_embeddings)))\n\u001b[0;32m   1318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(config\u001b[39m.\u001b[39md_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mshared\u001b[39m.\u001b[39mnum_embeddings, bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\admindc\\anaconda3\\envs\\tf_devia\\lib\\site-packages\\transformers\\models\\pegasus\\modeling_pegasus.py:1165\u001b[0m, in \u001b[0;36mPegasusModel.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(config)\n\u001b[0;32m   1164\u001b[0m padding_idx, vocab_size \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mpad_token_id, config\u001b[39m.\u001b[39mvocab_size\n\u001b[1;32m-> 1165\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshared \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mEmbedding(vocab_size, config\u001b[39m.\u001b[39;49md_model, padding_idx)\n\u001b[0;32m   1167\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m PegasusEncoder(config, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshared)\n\u001b[0;32m   1168\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder \u001b[39m=\u001b[39m PegasusDecoder(config, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshared)\n",
      "File \u001b[1;32mc:\\Users\\admindc\\anaconda3\\envs\\tf_devia\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:144\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[1;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m _weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty((num_embeddings, embedding_dim), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs),\n\u001b[0;32m    143\u001b[0m                             requires_grad\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m _freeze)\n\u001b[1;32m--> 144\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset_parameters()\n\u001b[0;32m    145\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlist\u001b[39m(_weight\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m [num_embeddings, embedding_dim], \\\n\u001b[0;32m    147\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mShape of weight does not match num_embeddings and embedding_dim\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\admindc\\anaconda3\\envs\\tf_devia\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:153\u001b[0m, in \u001b[0;36mEmbedding.reset_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreset_parameters\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     init\u001b[39m.\u001b[39;49mnormal_(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight)\n\u001b[0;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fill_padding_idx_with_zero()\n",
      "File \u001b[1;32mc:\\Users\\admindc\\anaconda3\\envs\\tf_devia\\lib\\site-packages\\torch\\nn\\init.py:155\u001b[0m, in \u001b[0;36mnormal_\u001b[1;34m(tensor, mean, std)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39moverrides\u001b[39m.\u001b[39mhas_torch_function_variadic(tensor):\n\u001b[0;32m    154\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39moverrides\u001b[39m.\u001b[39mhandle_torch_function(normal_, (tensor,), tensor\u001b[39m=\u001b[39mtensor, mean\u001b[39m=\u001b[39mmean, std\u001b[39m=\u001b[39mstd)\n\u001b[1;32m--> 155\u001b[0m \u001b[39mreturn\u001b[39;00m _no_grad_normal_(tensor, mean, std)\n",
      "File \u001b[1;32mc:\\Users\\admindc\\anaconda3\\envs\\tf_devia\\lib\\site-packages\\torch\\nn\\init.py:19\u001b[0m, in \u001b[0;36m_no_grad_normal_\u001b[1;34m(tensor, mean, std)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_no_grad_normal_\u001b[39m(tensor, mean, std):\n\u001b[0;32m     18\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> 19\u001b[0m         \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49mnormal_(mean, std)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "summarize = pipeline(\"summarization\",\n",
    "                     model=\"tuner007/pegasus_summarizer\")\n",
    "                    #  model=\"joelito/plain_english_contracts_summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Your entitlement to benefits as a full-time, voluntary part-time '\n",
      " 'worker.Hello MAELLE BERTHET,By this letter, we inform you of your '\n",
      " 'entitlement to benefits as a full-time, voluntary part-time worker, '\n",
      " 'following your request or declaration of an amending event, taking place on '\n",
      " '10/12/2022.')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(ret[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'By this letter, we inform you of your entitlement to benefits as a full-time, voluntary part-time worker, following your request or declaration of an'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(ret[0]['translation_text'], max_length=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (3970498777.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[21], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    def remove_n(line=\"Madame, La CAPAC de BRUXELLES a reçu votre courrier le 28/12/2022 pour la demande suivante : Je termine une formation professionnelle à partir du 10/12/2022. Vous avez remis ou rempli sur place les documents suivants\u001b[0m\n\u001b[1;37m                                                                                                                                                                                                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "def remove_n(line):\n",
    "    return line.replace(\"\\n\", \" \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = '''Madame, La CAPAC de BRUXELLES a reçu votre courrier le 28/12/2022 pour la demande suivante : Je termine une formation professionnelle à partir du 10/12/2022. Vous avez remis ou rempli sur place les documents suivants\n",
    "C91\n",
    "Vous devez nous fournir les documents suivants\n",
    "(sous réserve de demandes complémentaires suite au contrôle de l'ONEM)\n",
    "Aucun autre formulaire ne vous est actuellement réclamé. Si, après l'examen des documents électroniques\n",
    "nécessaires à votre dossier, celui-ci est considéré comme valable, il sera aussitôt transmis à l'Onem. Dans le cas\n",
    "contraire, un courrier complémentaire vous sera adressé dans les prochains jours.\n",
    "ATTENTION : Toute introduction tardive peut conduire à un retard dans les paiements ou à la perte des allocations. L'ONEM ne peut décider de\n",
    "votre droit à des allocations que si votre dossier est complet. Ce n'est qu'après approbation de l'ONEM que la CAPAC vous paiera.\n",
    "Votre inscription en tant que demandeur d'emploi\n",
    "Vous ne devez pas vous réinscrire.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Madame, La CAPAC de BRUXELLES a reçu votre courrier le 28/12/2022 pour la demande suivante : Je termine une formation professionnelle à partir du 10/12/2022. Vous avez remis ou rempli sur place les documents suivants C91 Vous devez nous fournir les documents suivants (sous réserve de demandes complémentaires suite au contrôle de l'ONEM) Aucun autre formulaire ne vous est actuellement réclamé. Si, après l'examen des documents électroniques nécessaires à votre dossier, celui-ci est considéré comme valable, il sera aussitôt transmis à l'Onem. Dans le cas contraire, un courrier complémentaire vous sera adressé dans les prochains jours. ATTENTION : Toute introduction tardive peut conduire à un retard dans les paiements ou à la perte des allocations. L'ONEM ne peut décider de votre droit à des allocations que si votre dossier est complet. Ce n'est qu'après approbation de l'ONEM que la CAPAC vous paiera. Votre inscription en tant que demandeur d'emploi Vous ne devez pas vous réinscrire.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_2 = remove_n(line)\n",
    "line_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4b93b6c6ed4921a990330a8f634a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fede17ffb54db9af26c06cd579a9ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/864M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83ec24c5fed4a5ea0c3bbea93bae7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/1.12M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58dbd18f4ba54fcf84c9996162922f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.63M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarizer_fr = pipeline(\"summarization\",\n",
    "                         model=\"moussaKam/barthez-orangesum-title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"Demande d'allocations : la CAPAC reçoit votre courrier le 28/12/2022\"}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer_fr(line_2, max_length=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_devia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
